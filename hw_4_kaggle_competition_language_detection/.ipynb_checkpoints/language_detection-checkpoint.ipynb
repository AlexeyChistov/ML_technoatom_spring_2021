{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Exploratory-Data-Analysis-and-Metric\" data-toc-modified-id=\"Exploratory-Data-Analysis-and-Metric-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Exploratory Data Analysis and Metric</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Submit\" data-toc-modified-id=\"Submit-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Submit</a></span></li><li><span><a href=\"#Homework\" data-toc-modified-id=\"Homework-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Homework</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:20:04.248094Z",
     "start_time": "2021-04-14T09:20:01.514286Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:22:23.147917Z",
     "start_time": "2021-04-14T09:22:22.689929Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/alexey/MLbase_2021_spring/lecture06/data/train.csv')\n",
    "test_df = pd.read_csv('/home/alexey/MLbase_2021_spring/lecture06/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sentence = \\\n",
    "    train_df.sentence.str.translate(str.maketrans('', '', string.punctuation + string.digits)).str.lower()\n",
    "test_df.sentence = \\\n",
    "    test_df.sentence.str.translate(str.maketrans('', '', string.punctuation + string.digits)).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop_duplicates(inplace=True, keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В релиз не вошло, но в \"train.csv\" встречается большое количество ошибок, как правило это повторы, как и было анонсированно. Поэтому подчищаем наш трейн вместе с самими дубликатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pensez à la communication  le discours  les ge...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>můžete si ji pronajmout  vzít na splátky  koup...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>každý starosta pochopil  že když mají tyto for...</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>det är ytterligare bevis  men ändå — jag kriti...</td>\n",
       "      <td>sv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>كان الأمر لا يصدق</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159628</th>\n",
       "      <td>そんな所で捕まっている片手は 億の人々と繫がる命綱なのです</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159629</th>\n",
       "      <td>първоначално се опитах да направя думите quot ...</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159630</th>\n",
       "      <td>ho appreso che ha a che fare con lapos attenzi...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159631</th>\n",
       "      <td>e os edifícios não se limitam a apenas evocar ...</td>\n",
       "      <td>pt-br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159632</th>\n",
       "      <td>la « danse d ’ entrée du mariage jk » est deve...</td>\n",
       "      <td>fr-ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2733564 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sentence language\n",
       "0        pensez à la communication  le discours  les ge...       fr\n",
       "1        můžete si ji pronajmout  vzít na splátky  koup...       cs\n",
       "2        každý starosta pochopil  že když mají tyto for...       cs\n",
       "3        det är ytterligare bevis  men ändå — jag kriti...       sv\n",
       "4                                       كان الأمر لا يصدق        ar\n",
       "...                                                    ...      ...\n",
       "3159628                      そんな所で捕まっている片手は 億の人々と繫がる命綱なのです       ja\n",
       "3159629  първоначално се опитах да направя думите quot ...       bg\n",
       "3159630  ho appreso che ha a che fare con lapos attenzi...       it\n",
       "3159631  e os edifícios não se limitam a apenas evocar ...    pt-br\n",
       "3159632  la « danse d ’ entrée du mariage jk » est deve...    fr-ca\n",
       "\n",
       "[2733564 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.values[:, 1]\n",
    "label_encoder = LabelEncoder().fit(train_df.values[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['תודה לכם ',\n",
       "       'precisamos de compaixão para começar  e autointeresse sensato para lidar com tudo com seriedade ',\n",
       "       '這個增長相當大 ， 並且它將引發經濟的增長 。', ...,\n",
       "       'prečo  lebo je to v každom z nás ',\n",
       "       'ibm과 usda과 같이 하고 있습니다  이를 저작권 보호가 없는 퍼블릭 도메인에 공개합니다  왜냐하면 마르스는 모든사람이 이 정보에 접근해서 코코아의 생산성이 더 향상되고 지속가능해지기는데 모두가 돕기를 원하기 때문입니다 ',\n",
       "       '换而言之 ， 我们的恐惧让我们想到未来 。'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_lan_set = train_df.language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fr', 'cs', 'sv', 'ar', 'hr', 'id', 'az', 'ru', 'he', 'ja', 'de',\n",
       "       'nl', 'zh-tw', 'ko', 'it', 'hu', 'en', 'vi', 'bg', 'th', 'zh-cn',\n",
       "       'tr', 'el', 'nb', 'es', 'pl', 'ro', 'sr', 'fa', 'da', 'uk',\n",
       "       'pt-br', 'ka', 'zh', 'sl', 'sk', 'lt', 'my', 'mn', 'fr-ca', 'mk',\n",
       "       'fi', 'sq', 'pt', 'eu', 'hy', 'ta', 'hi', 'et', 'ku', 'gl', 'bn',\n",
       "       'mr', 'bs', 'be', 'ms', 'eo', 'ur', 'kk'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_lan_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Поскольку, как и было анонсированно, классы у нас не сбалансированы, создадим подвыборку размера: \n",
    "\n",
    "$n_{min} \\times m,$\n",
    "где $n_{min}$ - количество текстов для самого минорного языка, m - количество языков.\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_size = 2000\n",
    "X_train = np.array([])\n",
    "y_train = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-c1b9805978da>:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for lang in tqdm_notebook(uniq_lan_set):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0a11205da542a68460b85161f403f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lang in tqdm_notebook(uniq_lan_set):\n",
    "    df_buffer = train_df[train_df.language == lang]\n",
    "    y_train = np.hstack([y_train, df_buffer.values[:balanced_size, 1]])\n",
    "    X_train = np.hstack([X_train, df_buffer.values[:balanced_size, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 352 µs, sys: 0 ns, total: 352 µs\n",
      "Wall time: 363 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1, 3), analyzer='char', min_df=6, max_df=0.6)),\n",
    "    ('model', SGDClassifier(random_state=42, loss='log'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:22:30.060126Z",
     "start_time": "2021-04-14T09:22:30.056241Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipe = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(ngram_range=(1, 3), analyzer='char', min_df=6, max_df=0.6)),\n",
    "#     ('model', MultinomialNB())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 12.5 s, total: 1min 45s\n",
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='char', max_df=0.6, min_df=6,\n",
       "                                 ngram_range=(1, 3))),\n",
       "                ('model', SGDClassifier(loss='log', random_state=42))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Ниже реализуется предикт батчами по 50k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.65 s, sys: 59.7 ms, total: 9.71 s\n",
      "Wall time: 9.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = pipe.predict(X_test[0:50000]) \n",
    "# Небольшой костыль, вынесено из цикла, \n",
    "# тк до релизной версии использовал partial_predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e0d400a778475992fb7d8a33c0e224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 57s, sys: 4.01 s, total: 9min 1s\n",
      "Wall time: 9min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_step = 50000\n",
    "for i in tqdm_notebook(range(batch_step, X_test.shape[0], batch_step)):\n",
    "    if i >= X_test.shape[0] - batch_step:\n",
    "        k = X_test.shape[0]\n",
    "        y_pred = np.hstack([y_pred, pipe.predict(X_test[i:k])])\n",
    "\n",
    "    else:\n",
    "        k = i + batch_step\n",
    "        y_pred = np.hstack([y_pred, pipe.predict(X_test[i:k])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2784634,) (2784634,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'index': np.arange(X_test.shape[0], dtype=int), 'language': label_encoder.inverse_transform(y_pred)})\n",
    "df.to_csv('language_detection_submission_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
